#+TITLE: Process preliminary RAMA data
#+AUTHOR: Deepak Cherian
#+OPTIONS: timestamp:nil title:t html5-fancy:t html-style:nil html-scripts:nil

#+LATEX_CLASS: dcnotebook

#+HTML_HEAD: <link rel="stylesheet" href="notebook.css" type="text/css" />
* emails
** March 27, 2017 Sonya
#+BEGIN_QUOTE

Hi Deepak,

I've placed two sets of pre-calibrated subsurface data into ftp://ftp.pmel.noaa.gov/OCRD/tao/ForDeepak/, as well as the post-calibrated salinity files from ra107 *(post cals are not available yet for the ra122 data)*. The ~.flg files are text files containing the data (with the pre or post-calibrations applied). The ~sum files are log files listing the instruments in each mooring along with some notes about them (we add more notes to these as we process the mooring). In the "postcal" directory you'll find, alongside the post-calibrated ~flg files, *two files containing the pre-cal and post-cal coefficients, in case you're curious (since they've already been applied, you most likely won't need them).* Note that in typical salinity processing,
1. [X] I would first flag data that appeared bad and unfixable,
2. [X] and then I'd apply a pre-to-post-cal linear interpolation across the data to correct for large-scale drifts (i.e. the first data value in the interpolated output would have a pre-cal applied, while the last value would have a post-cal applied, with the values interpolated in between).
3. [X] After that I'd compare the end points with previous and subsequent moorings at the same site, as well as any available CTDs,
4. [ ] and I'd check inter-depth differences for density inversions.
5. [ ] Using these three pieces of information, I'd manually adjust the data as needed (sometimes with dozens of adjustments needed to eliminate large-scale density inversions and bring various depths back into the mixed layer) before filtering them (into hourly data) and releasing them.

I hope this helps. Take care and please let me know if you need anything else, -Sonya

p.s. The 10m current data will be posted later, - I'll let you know when those are posted as well....

#+END_QUOTE
* Functions :noexport:

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results
  import numpy as np
  import matplotlib as mpl
  import matplotlib.pyplot as plt
  import datetime as dt
  import cmocean as cmo
  from copy import copy

  mpl.rcParams['savefig.transparent'] = True
  mpl.rcParams['figure.figsize'] = [6.5, 6.5]
  mpl.rcParams['figure.dpi'] = 180
  mpl.rcParams['axes.facecolor'] = 'None'

  # ra107['sal][ra107['sal'] > 40] = np.NaN

  def CleanSalinity(salinity):
    """ Adds NaNs in place of missing values. """
    import numpy as np

    salinity = np.float32(salinity)

    if salinity > 39:
      salinity = np.nan

    return salinity

  def ProcessDate(datestr):
    """ Takes in string of form YYYYydayHHMM and returns python datetime object."""
    import datetime as dt

    year = int(datestr[0:4])
    yday = int(datestr[4:7])
    hour = int(datestr[7:9])
    mins = int(datestr[9:11])

    date = dt.datetime(year=year, month=1, day=1) \
			     +  dt.timedelta(days=yday-1, hours=hour, minutes=mins)

    return date

  sal = np.dtype([('date', dt.datetime),
		  ('sal', [('1', np.float32),
                           ('10', np.float32),
                           ('20', np.float32),
                           ('40', np.float32),
                           ('60', np.float32),
                           ('100', np.float32)]),
		  ('QQQQQQ', np.uint32),
		  ('SSSSSS', np.uint32)])

  temp = np.dtype([('date', dt.datetime),
		   ('temp', [('1', np.float32),
                             ('10', np.float32),
                             ('13', np.float32),
                             ('20', np.float32),
                             ('40', np.float32),
                             ('60', np.float32),
                             ('80', np.float32),
                             ('100', np.float32),
                             ('120', np.float32),
                             ('140', np.float32),
                             ('180', np.float32),
                             ('300', np.float32),
                             ('500', np.float32)]),
		   ('QQQQQQ', np.uint32),
		   ('SSSSSS', np.uint32)])

  dens = np.dtype([('date', dt.datetime),
		   ('dens', [('1', np.float32),
                            ('10', np.float32),
                            ('20', np.float32),
                            ('40', np.float32),
                            ('60', np.float32),
                            ('100', np.float32)]),
		   ('QQQQQQ', np.uint32),
		   ('SSSSSS', np.uint32)])
#+END_SRC

#+RESULTS:

* RAMA13 (ra-107)
** read & interpolate all data
From Sonya:
#+BEGIN_quote
  I'd apply a /pre-to-post-cal linear interpolation/ across the data to correct for large-scale drifts (i.e. the first data value in the interpolated output would have a pre-cal applied, while the last value would have a post-cal applied, with the values interpolated in between).
#+END_QUOTE

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results

  cnv = {0:ProcessDate}
  for jj in np.arange(1,7):
      cnv[jj] = CleanSalinity;

  ra107pre = np.loadtxt('../TAO_raw/sal107a.flg', skiprows=5, dtype=sal,
			converters=cnv)

  ra107post = np.loadtxt('../TAO_raw/postcal/sal107a.flg', skiprows=5,
			 dtype=sal, converters=cnv)

  # setup a mooring dictionary
  ra107 = dict([])
  ra107['date'] = ra107pre['date']
  ra107['sal-pre'] = ra107pre['sal']
  ra107['sal-post'] = ra107post['sal']
  ra107['sal']  = dict([])
  ra107['temp'] = dict([])
  ra107['dens'] = dict([])
  ra107['dens-pre'] = dict([])
  ra107['dens-post'] = dict([])

  ra107pre = np.loadtxt('../TAO_raw/dens107a.flg', skiprows=5,
			dtype=dens, converters=cnv)
  ra107['dens-pre'] = ra107pre['dens']

  ra107post = np.loadtxt('../TAO_raw/postcal/dens107a.flg', skiprows=5,
			 dtype=dens, converters=cnv)
  ra107['dens-post'] = ra107pre['dens']

  # now for pre-calib temperature
  cnv = {0:ProcessDate}
  for jj in np.arange(1,14):
      cnv[jj] = CleanSalinity;
  ra107pre = np.loadtxt('../TAO_raw/temp107a.flg', skiprows=5,
			dtype=temp, converters=cnv)
  ra107['temp'] = ra107pre['temp']

  Ntime = len(ra107pre['date'])

  weight_pre = np.arange(Ntime-1,-1,-1)/(Ntime-1)
  weight_post = np.arange(0,Ntime)/(Ntime-1)

  for depth in ra107['sal-pre'].dtype.names:
      ra107['sal'][depth] = weight_pre * ra107['sal-pre'][depth] \
                            + weight_post * ra107['sal-post'][depth]
      ra107['dens'][depth] = weight_pre * ra107['dens-pre'][depth] \
                            + weight_post * ra107['dens-post'][depth]

#+END_SRC

#+RESULTS:

** Salinity
*** Difference between pre- and post-salinity.

Post-cal salinity is roughly 0.05 psu lower everywhere.
#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/rama13-sal-pre-post-cal.png

  plt.plot_date(ra107pre['date'],
		ra107pre['sal']['10'] - ra107post['sal']['10'], '-')
  plt.title('RAMA13 pre-cal salinity - post-cal salinity')
#+END_SRC

#+RESULTS:
[[file:images/rama13-sal-pre-post-cal.png]]
*** Compare pre- and post-cal
#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/rama13-interp-pre-post-sal.png
  depth = '10'
  plt.figure()
  plt.plot(ra107['sal'][depth] - ra107['sal-pre'][depth], label='interp-pre')
  plt.plot(ra107['sal'][depth] - ra107['sal-post'][depth], label='interp-post')
  plt.axhline(0)
  plt.legend()
  plt.title(depth + 'm depth')
#+END_SRC

#+RESULTS:
[[file:images/rama13-interp-pre-post-sal.png]]

Nothing crazy in the interpolated product. Spiky at the surface, perhaps that's expected.

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/rama13-interp-salinity.png
  plt.figure()

  for depth in ra107['sal'].dtype.names:
	plt.plot_date(ra107['date'][0:-1:6],
                      ra107['sal'][depth][0:-1:6], '-',
                      label=depth, linewidth=1)

  plt.legend()
  plt.title('ra-107 / RAMA13 interpolated pre-cal post-cal salinity product')

#+END_SRC

#+RESULTS:
[[file:images/rama13-interp-salinity.png]]
** Temperature
*** Read in netCDF data
This is the same as date read from pre-cal .flg file.

There is no post-cal for temperature.

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports none
  tempfilename = '../t12n90e_10m.cdf'

  import netCDF4 as nc

  tempfile = nc.Dataset(tempfilename)

  # t0 = np.datetime64(tempfile['time'].units[14:])
  t0 = dt.datetime.strptime(tempfile['time'].units[14:],
			    '%Y-%m-%d %H:%M:%S')
  timevec = np.array([t0 + dt.timedelta(minutes=tt.astype('float')) \
                      for tt in tempfile['time'][0:]])

  ind107start = np.argmin(np.abs(timevec - ra107['date'][0]))
  ind107stop = np.argmin(np.abs(timevec - ra107['date'][-1]))

  temp_matrix = tempfile['T_20'][ind107start:ind107stop+1].squeeze()

  # save processed temperature product
  for index, zz in enumerate(np.int32(tempfile['depth'][:])):
      ra107['temp-proc'][str(zz)] = temp_matrix[:,index]

  # now for pre-calib temperature
  cnv = {0:ProcessDate}
  for jj in np.arange(1,14):
      cnv[jj] = CleanSalinity;

  ra107pre = np.loadtxt('../TAO_raw/temp107a.flg', skiprows=5, dtype=temp,
			converters=cnv)

  ra107['temp'] = ra107pre['temp']
#+END_SRC

#+RESULTS:
*** Compare fully-processed and "preliminary" data = no difference :noexport:
#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports none :file images/ra107-pre-proc-temp.png
  for index, zz in enumerate(['1', '10', '20', '40']):
      plt.subplot(4,1,index+1)
      plt.plot_date(ra107['date'],
                    ra107['temp-proc'][zz]-ra107['temp'][zz],
                    '-', linewidth=1)
#+END_SRC

#+RESULTS:
[[file:ra107-pre-proc-temp.png]]
** Density inversions
*** How many exist in 10 minute data

The percentage of valid data with N² < 0
#+BEGIN_SRC ipython :session :eval never-export :exports results
  import seawater as sw

  ra107['salarr'] = np.array([ra107['sal']['1'],
			      ra107['sal']['10'],
			      ra107['sal']['20'],
			      ra107['sal']['40'],
			      ra107['sal']['60'],
			      ra107['sal']['100']])

  ra107['temparr'] = np.array([ra107['temp']['1'],
			       ra107['temp']['10'],
			       ra107['temp']['20'],
			       ra107['temp']['40'],
			       ra107['temp']['60'],
			       ra107['temp']['100']])

  ra107['densarr'] = np.array([ra107['dens']['1'],
			       ra107['dens']['10'],
			       ra107['dens']['20'],
			       ra107['dens']['40'],
			       ra107['dens']['60'],
			       ra107['dens']['100']])

  ra107['presarr'] = np.array([1*np.ones(ra107['temp']['1'].shape),
			       10*np.ones(ra107['temp']['1'].shape),
			       20*np.ones(ra107['temp']['1'].shape),
			       40*np.ones(ra107['temp']['1'].shape),
			       60*np.ones(ra107['temp']['1'].shape),
			       100*np.ones(ra107['temp']['1'].shape)])

  dSdz = -np.diff(ra107['salarr'], axis=0)/np.diff(ra107['presarr'], axis=0)
  dTdz = -np.diff(ra107['temparr'], axis=0)/np.diff(ra107['presarr'], axis=0)


  N2,_,p_ave = sw.bfrq(ra107['salarr'], ra107['temparr'], ra107['presarr'], 12)
  ra107['N2'] = N2

  # Percentage of valid data that yields N² < 0
  mask1 = ~np.isnan(N2[1,:])
  mask2 = ~np.isnan(N2[2,:])

  table = [list(p_ave[:,0]),
           [np.round(len(n[n<0])/len(n)*100) for n in # % N² < 0
            [N2[i,~np.isnan(N2[i,:])] for i in range(N2.shape[0])]],
           [np.round(len(s[s>0])/len(s)*100) for s in # % dS/dz > 0
            [dSdz[i,~np.isnan(dSdz[i,:])] for i in range(dSdz.shape[0])]],
           [np.round(len(s[s<0])/len(s)*100) for s in # % dT/dz > 0
            [dTdz[i,~np.isnan(dTdz[i,:])] for i in range(dTdz.shape[0])]]]

  table[0].insert(0, 'Depth (m)')
  table[1].insert(0, '% N² < 0')
  table[2].insert(0, '% dS/dz > 0')
  table[3].insert(0, '% dT/dz < 0')

  table
#+END_SRC

#+RESULTS:
| Depth (m)   |  5.5 | 15.0 | 30.0 | 50.0 | 80.0 |
| % N² < 0    | 61.0 | 12.0 | 21.0 |  0.0 |  0.0 |
| % dS/dz > 0 | 53.0 | 19.0 | 28.0 |  1.0 | 15.0 |
| % dT/dz < 0 | 69.0 | 47.0 | 23.0 |  7.0 |  0.0 |

*** Where do these occur?

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/rama13-N2-negative.png

  for index,zz in enumerate(['10', '20', '40']):
      plt.subplot(3,1,index+1)
      datenum = mpl.dates.date2num(ra107['date'])
      plt.plot(datenum, ra107['sal'][zz], 'k-',
	       linewidth=1)
      if index == 0:
          mask = ra107['N2'][0,:] < 0

      if index == 1:
          mask = np.logical_or(ra107['N2'][0,:] < 0,
                               ra107['N2'][1,:] < 0)

      if index == 1:
          mask = ra107['N2'][1,:] < 0

      plt.plot(datenum[mask], ra107['sal'][zz][mask],
	       'r.', markersize=2)

      # plt.xlim([735260, 735280])
#+END_SRC

#+RESULTS:
[[file:images/rama13-N2-negative.png]]
*** Compare with density from .flg file

Using density from .flg files is consistent. There seem be a lot of density inversions between 10m and 20m depths; especially at the beginning of the record.

winter convection?

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/rama13-density-diff.png
  N2 = np.zeros([2, len(ra107['dens']['10'])])
  N2[0,:] = -9.81/1028 * (ra107['dens']['10']-ra107['dens']['20'])/10
  N2[1,:] = -9.81/1028 * (ra107['dens']['20']-ra107['dens']['40'])/20

  tend = 500;
  monthsFmt = mpl.dates.DateFormatter("%d-%m")
  hax = plt.subplot(311)
  plt.plot(ra107['date'],
           ra107['dens']['10'] - ra107['dens']['1'], linewidth=1)
  plt.axhline(0, color='k')
  plt.ylabel('Δρ 10m-1m')
  hax.xaxis.set_major_formatter(monthsFmt)

  hax = plt.subplot(312)
  plt.plot(ra107['date'],
           ra107['dens']['20'] - ra107['dens']['10'], linewidth=1)
  plt.axhline(0, color='k')
  plt.ylabel('Δρ 20m-10m')
  hax.xaxis.set_major_formatter(monthsFmt)

  hax = plt.subplot(313)
  plt.plot_date(ra107['date'], ra107['dens']['40'] - ra107['dens']['20'], '-', linewidth=1)
  plt.axhline(0, color='k')
  plt.ylabel('Δρ 40m-20m')
  hax.xaxis.set_major_formatter(monthsFmt)

#+END_SRC

#+RESULTS:
[[file:images/rama13-density-diff.png]]

#+BEGIN_SRC ipython :session :tangle yes :exports results :eval never-export :file images/rama13-dens-inversion-zoom.png
  tend = 500;
  monthsFmt = mpl.dates.DateFormatter("%d-%m")

  plt.plot(ra107['date'][0:tend],
           ra107['dens']['20'][0:tend] - ra107['dens']['10'][0:tend], linewidth=1)
  plt.axhline(0, color='k')
  plt.ylabel('Δρ 20m-10m')
  hax.xaxis.set_major_formatter(monthsFmt)

#+END_SRC

#+RESULTS:
[[file:images/rama13-dens-inversion-zoom.png]]

*** Funny density offset/trends appear to result from salinity.
#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/rama13-sal-diff.png
  N2 = np.zeros([2, len(ra107['sal']['10'])])
  N2[0,:] = -9.81/1028 * (ra107['sal']['10']-ra107['sal']['20'])/10
  N2[1,:] = -9.81/1028 * (ra107['sal']['20']-ra107['sal']['40'])/20

  limy = [-0.2, 0.4]

  tend = 500;
  monthsFmt = mpl.dates.DateFormatter("%d-%m")
  hax = plt.subplot(311)
  plt.plot(ra107['date'],
           ra107['sal']['10'] - ra107['sal']['1'], linewidth=1)
  plt.axhline(0, color='k')
  plt.ylabel('ΔS 10m-1m')
  plt.ylim(limy)
  hax.xaxis.set_major_formatter(monthsFmt)

  hax = plt.subplot(312)
  plt.plot(ra107['date'],
           ra107['sal']['20'] - ra107['sal']['10'], linewidth=1)
  plt.axhline(0, color='k')
  plt.ylabel('ΔS 20m-10m')
  plt.ylim(limy)
  hax.xaxis.set_major_formatter(monthsFmt)

  hax = plt.subplot(313)
  plt.plot_date(ra107['date'], ra107['sal']['40'] - ra107['sal']['20'], '-', linewidth=1)
  plt.axhline(0, color='k')
  plt.ylabel('ΔS 40m-20m')
  plt.ylim(limy)
  hax.xaxis.set_major_formatter(monthsFmt)

  plt.show()
#+END_SRC

#+RESULTS:
[[file:images/rama13-sal-diff.png]]
*** Contributors to negative N²
Salinity appears to be the controlling factor generally.

#+BEGIN_SRC ipython :session :tangle yes :exports results :eval never-export :file images/rama13-dρdz.png

  class MidpointNormalize(mpl.colors.Normalize):
      def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):
          self.midpoint = midpoint
          mpl.colors.Normalize.__init__(self, vmin, vmax, clip)

      def __call__(self, value, clip=None):
          # I'm ignoring masked values and all kinds of edge cases to make a
          # simple example...
          x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]
          return np.ma.masked_array(np.interp(value, x, y))

  tindex = np.arange(0,dSdz.shape[1])
  # ra107['N2'][ra107['N2'] > 0.05] = np.nan;

  hax = plt.subplot(311)
  plt.pcolormesh(tindex, -ra107['presarr'],
		 1e6*-7.6e-5*np.ma.masked_array(dSdz, np.isnan(dSdz)),
		 norm=MidpointNormalize(midpoint=0.),
		 cmap=cmo.cm.balance)
  plt.title('β dS/dz * 1e6')
  plt.clim(-3, 12)
  plt.colorbar(extend='min')

  hax = plt.subplot(312)
  plt.pcolormesh(tindex, -ra107['presarr'],
		 1e6*-1.7e-4*np.ma.masked_array(dTdz, np.isnan(dTdz)),
		 norm=MidpointNormalize(midpoint=0.),
		 cmap=cmo.cm.balance)
  plt.colorbar(extend='min')
  plt.clim(-3, 12)
  plt.title('-α dT/dz * 1e6')

  hax = plt.subplot(313)
  mycmap = copy(cmo.cm.ice_r)
  mycmap.set_bad(color='w')
  mycmap.set_under(color='r')
  mynorm = mpl.colors.Normalize(vmin=0., vmax=np.nanmax(ra107['N2']))

  plt.pcolormesh(tindex, -ra107['presarr'],
		 np.ma.masked_array(ra107['N2'], np.isnan(ra107['N2'])),
		 cmap=mycmap, norm=mynorm)
  plt.axhline(-15, color='k'); plt.axhline(-30, color='k')
  plt.colorbar(extend='min')
  plt.title('N² (negative in red)')

  plt.tight_layout()
  plt.show()

#+END_SRC

#+RESULTS:
[[file:images/rama13-dρdz.png]]

Let's try a better way.

Looks like both dT/dz < 0, dS/dz > 0 (colder, saltier water on top) are responsible.

Though most points have dS/dz > 0.

#+BEGIN_SRC ipython :session :tangle yes :exports results :eval never-export :file images/rama13-neg-N²-scatter.png

  for ii in [1,2]:
      plt.subplot(1,2,ii)
      mask = N2[ii,:] < 0
      plt.hexbin(7.6e-1*dSdz[ii,mask], 1.7*dTdz[ii,mask], mincnt=10)
      plt.axis('square')
      plt.axhline(0, color='k', alpha=0.5);
      plt.axvline(0, color='k', alpha=0.5)
      if ii is 1:
          plt.xlim([-0.005, 0.005]); plt.ylim([-0.005, 0.005])
      if ii is 2:
          plt.xlim([-0.0025, 0.0025]); plt.ylim([-0.0025, 0.0025])

      plt.xlabel('β dS/dz * 1e4'); plt.ylabel('α dT/dz * 1e4')
      plt.title(str(p_ave[ii,0]) + 'm')

  plt.gcf().suptitle('N² < 0 points binned', y=0.75)
  plt.tight_layout()
  plt.show()
#+END_SRC

#+RESULTS:
[[file:images/rama13-neg-N²-scatter.png]]


* RAMA14 (ra-122)

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results
  ra122read = np.loadtxt('../TAO_raw/sal122a.flg', skiprows=5, dtype=sal,
			 converters={0:ProcessDate,
			             1:CleanSalinity,
			             2:CleanSalinity,
			             3:CleanSalinity,
			             4:CleanSalinity,
			             5:CleanSalinity,
			             6:CleanSalinity})

  ra122 = dict([])
  ra122['date'] = ra122read['date']
  ra122['sal']  = ra122read['sal']
  ra122['temp'] = dict([])
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/rama14-pre-cal-salinity.png
    plt.figure()

    for depth in ra122['sal'].dtype.names:
	  plt.plot_date(ra122['date'][0:-1:6],
			ra122['sal'][depth][0:-1:6], '-',
			label=depth, linewidth=1)

    plt.legend()
    plt.title('ra-122 / RAMA14 pre-cal salinity product')
#+END_SRC

#+RESULTS:
[[file:images/rama14-pre-cal-salinity.png]]

* Full record
** What are the differences between end of RAMA13 and start of RAMA14

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results
  ramadiff = np.dtype([('depth', np.int32),
                       ('ΔS', np.float32),
                       ('Δt', dt.timedelta)])

  diff = np.zeros((6,), dtype=ramadiff)

  for index,depth in enumerate(ra107['sal'].keys()):
      r13 = ra107['sal'][depth]
      sal13 = r13[~np.isnan(r13)]
      date13 = ra107['date'][~np.isnan(r13)]

      diff[index] = (int(depth),
                     ra122['sal'][depth][0] - r13[-1],
                     ra122['date'][0] - date13[-1])

  diff
#+END_SRC

#+RESULTS:
: array([(  1,         nan, datetime.timedelta(27, 61200)),
:        ( 10,  0.02700043, datetime.timedelta(0, 46200)),
:        ( 20,  0.01599884, datetime.timedelta(0, 46200)),
:        ( 40,  0.47800064, datetime.timedelta(0, 46200)),
:        ( 60,  0.0359993 , datetime.timedelta(0, 46200)),
:        (100,  0.00300217, datetime.timedelta(0, 46200))],
:       dtype=[('depth', '<i4'), ('ΔS', '<f4'), ('Δt', 'O')])

(depth, ΔS, Δtime)

ra107 surface instrument failed a month before recovery.

The rest seem OK except for the 40m instrument: during recovery/deployment there is a big jump of 0.5 psu.

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/ra07-ra122-switch-period.png
  for index, depth in enumerate(ra107['sal'].keys()):
      if index == 0:
          continue

      hax = plt.subplot(6,1,index+1)

      plt.plot_date(ra107['date'][-100:-1],
	            ra107['sal'][depth][-100:-1],
	            'k*-', linewidth=1)
      plt.plot_date(ra122['date'][0:100],
	            ra122['sal'][depth][0:100],
	            'k*-', linewidth=1)

      if index < 5:
          hax.set_xticklabels([], visible=False)

      plt.title(depth+'m')

  plt.tight_layout()
#+END_SRC

#+RESULTS:
[[file:images/ra07-ra122-switch-period.png]]

** Plot full record - 10 min salinity

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/rama13-rama14-full-salinity.png

  dtime = 1
  for index, depth in enumerate(ra107['sal'].keys()):
       hax = plt.subplot(6,1,index+1)
       rama = ra107
       plt.plot_date(rama['date'][0:-1:dtime],
	             rama['sal'][depth][0:-1:dtime], 'k-',
	             label=depth, linewidth=1)

       rama = ra122
       plt.plot_date(rama['date'][0:-1:dtime],
	             rama['sal'][depth][0:-1:dtime], 'k-',
	             label=depth, linewidth=1)
       plt.title(depth + 'm')
       if index == 0:
           plt.title('RAMA 13 & 14 salinity | 1m')

       plt.ylim([31.5, 35.5])
       if index < 5:
            hax.set_xticklabels(labels=[], visible=False)

  plt.tight_layout()
#+END_SRC

#+RESULTS:
[[file:images/rama13-rama14-full-salinity.png]]

40m and 60m  instruments seem to be a lot noisier!

Emily thinks this is because of the thermocline being sloshed up and down by internal waves.

let's check distribution / variances - variances are only slightly higher.

#+BEGIN_SRC ipython :session :tangle yes :eval never-export :exports results :file images/rama13-rama14-sal-histograms.png
  def dcHist(var, bins=100, **kwargs):
    import numpy as np
    mpl.rcParams['figure.facecolor'] = 'None'
    plt.hist(var[~np.isnan(var)], bins,
             normed=True, alpha=0.7, **kwargs)

  for index, depth in enumerate(ra107['sal'].dtype.names):
    plt.subplot(3,2,index+1)
    dcHist(ra107['sal'][depth], label='13/107')
    dcHist(ra122['sal'][depth], label='14/122')
    plt.title(depth + 'm | var = '
              + str(np.nanvar(ra107['sal'][depth]))[0:5]
              + ' | var = '
              + str(np.nanvar(ra122['sal'][depth]))[0:5])
    if index == 0:
      plt.legend()

  plt.suptitle('Normalized histogram for 10min salinity', va='bottom')
  plt.tight_layout()

#+END_SRC

#+RESULTS:
[[file:images/rama13-rama14-sal-histograms.png]]
